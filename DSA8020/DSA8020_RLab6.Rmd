---
title: 'DSA 8020 R Lab 6: Non-parametric Regression and Shrinkage Methods'
author: "your name here, (the names of any collaborators)"
date: '`r format(Sys.time(), "%B %d, %Y")`'
output:
  pdf_document:
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Non-parametric Regression

The dataset \texttt{teengamb} concerns a study of teenage gambling in Britain.
Type `r ?teengamb' to get more deatils about the the dataset.
In this lab we will take the variables \texttt{gamble} as the response and \texttt{income} as the predictor.

*Data Source:* Ide-Smith & Lea, 1988, *Journal of Gambling Behavior*, 4, 110-118

1. Make a scatterplot to examine the relationship between the predictor \texttt{income} and the response \texttt{gamble}

**Code:**

```{r}
library(faraway)
data(teengamb)
```

2. Fit a curve to the data using regression spline with \texttt{df = 8}, produce a plot for the fit and a 95% confidence band (using *RegSplinePred <- predict(RegSplineFit, data.frame(income = xg), interval = "confidence")*) for that fit. Is a linear fit plausible?  

**Code:**

```{r}

```

**Answer:**

3. Fit a curve using either generalized additive models or smoothing splines and compare with the regression spline fit in problem 2.

**Code:**

```{r}

```

**Answer:**

## Ridge Regression andd LASSO: Meat spectrometry to determine fat content

A Tecator Infratec Food and Feed Analyzer working in the wavelength range 850 - 1050 nm by the Near Infrared Transmission (NIT) principle was used to collect data on samples of finely chopped pure meat. 215 samples were measured. For each sample, the fat content was measured along with a 100 channel spectrum of absorbances. Since determining the fat content via analytical chemistry is time consuming we would like to build a model to predict the fat content of new samples using the 100 absorbances which can be measured more easily.


*Data Source:* H. H. Thodberg (1993) "Ace of Bayes: Application of Neural Networks With Pruning", report no. 1132E, Maglegaardvej 2, DK-4000 Roskilde, Danmark

Load the data and partition the data into *training set* (the first 150 observations) and *testing set* (the remining 65 observations)

**Code:**

```{r}
data(meatspec, package = "faraway")
train <- 1:150; test <- 151:215
trainmeat <- meatspec[train,]
testmeat <- meatspec[test,]
```

4. Fit a linear regression with all the 100 predictors to the training set. Compute the root mean square error (RMSE) for the testing set. The code below shows how to compute the RMSE for the training set (aka in-sample prediction) and you will need to modify the code to compute the RMSE for the testing set

**Code:**

```{r}
lmFit <- lm(fat ~ ., data = trainmeat)
# Define a function to calculate RMSE
rmse <- function(pred, obs) sqrt(mean((pred - obs)^2))
# Computing RMSE for the training set
rmse(fitted(lmFit), trainmeat$fat)
```

**Answer:**

5. Fit a ridge regression (using Cross-Validation to select the "best" $\lambda$) and compute RMSE for the training set

**Code:**

```{r}

```

**Answer:**

6. Fit a LASSO (again using Cross-Validation to select the "best" $\lambda$) and compute RMSE for the training set

**Code:**

```{r}

```


**Answer:**

7. Fit a LASSO with all the data points (using the best $\lambda$) and report the number of non-zero regression coefficients

**Code:**

```{r}

```

**Answer:**
